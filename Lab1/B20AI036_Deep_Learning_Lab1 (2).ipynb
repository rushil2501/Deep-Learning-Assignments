{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "XaB-vCLnlELA"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from sklearn.model_selection  import train_test_split\n",
        "import torch #python #keras #tensorflow #pytorch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['sepal_length', ' sepal_width', 'petal_length', 'petal_width', 'class']\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', names=cols)\n",
        "def enc(col,name):\n",
        "  x = LabelEncoder()\n",
        "  lst  = x.fit_transform(df.iloc[:,col])\n",
        "  df[name] = lst[:]\n",
        "enc(4,'class')\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "print(df.info())\n",
        "print(len(pd.unique(y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VggESUsxto1t",
        "outputId": "c60be465-6958-4c66-b8a1-30ff57ea5ed6"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  150 non-null    float64\n",
            " 1    sepal_width  150 non-null    float64\n",
            " 2   petal_length  150 non-null    float64\n",
            " 3   petal_width   150 non-null    float64\n",
            " 4   class         150 non-null    int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 6.0 KB\n",
            "None\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = [np.random.random() for i in range(df.shape[1]-1)]\n",
        "bias = np.random.rand(1)\n",
        "lr = 0.01"
      ],
      "metadata": {
        "id": "vZC2HCCfes4U"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def activation(x):\n",
        "    if x>0:\n",
        "        return 1\n",
        "    return 0\n",
        "# def softmax(x):\n",
        "#   # Compute softmax along the rows of the input\n",
        "#   exponent = np.exp(x)\n",
        "#   return exponent/exponent.sum(axis=1,keepdims=True)\n",
        "  "
      ],
      "metadata": {
        "id": "v-yzx4RatkjJ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron(X, weights, bias):\n",
        "    l = np.dot(X, weights) + bias\n",
        "    # print('typeof l ',type(l))\n",
        "    # print(l)\n",
        "    return activation(l[0])\n",
        "def back_propagation(X,y,weights,bias,lr):\n",
        "  for i in range(2):\n",
        "    for j in range(X.shape[0]):\n",
        "      res = perceptron(X[j],weights,bias)\n",
        "      # print(type(res))\n",
        "      error = y[j]-res\n",
        "      weights += error*lr*X[j]\n",
        "      bias += lr*error\n",
        "  return weights,bias"
      ],
      "metadata": {
        "id": "-6u47PBbtm0V"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2L0FN6S-dqT",
        "outputId": "731e1693-5cf6-4654-b930-a7302c2ef04c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used one vs all classification method for predicting"
      ],
      "metadata": {
        "id": "fy2RT2kk-T2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy for class1 vs (class2 and class3):"
      ],
      "metadata": {
        "id": "n0CNnFA40bK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1=[0 if y[i]==0 else 1 for i in range(len(y))]\n",
        "print(len(y1))\n",
        "X_train1,X_test1,y_train1,y_test1 = train_test_split(X, y1, test_size=0.2)\n",
        "weights = [np.random.random() for i in range(df.shape[1]-1)]\n",
        "bias = np.random.rand(1)\n",
        "weights,bias = back_propagation(X_train1,y_train1,weights,bias,lr)\n",
        "y_pred1=[]\n",
        "for j in range(X_test1.shape[0]): \n",
        "    y_pred1.append(perceptron(X_test1[j],weights,bias))\n",
        "print(accuracy_score(y_test1, y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ThNohBFx3Se",
        "outputId": "c376a91a-57be-4ec2-f696-3cc4d98330d9"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150\n",
            "0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy for class2 vs (class1 and class3)"
      ],
      "metadata": {
        "id": "6n3mowdI06tB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y2=[0 if y[i]==1 else 1 for i in range(len(y))]\n",
        "X_train2,X_test2,y_train2,y_test2 = train_test_split(X, y2, test_size=0.2)\n",
        "weights,bias = back_propagation(X_train2, y_train2, weights, bias, lr)\n",
        "y_pred2=[]\n",
        "for j in range(X_test2.shape[0]): \n",
        "    y_pred2.append(perceptron(X_test2[j],weights,bias))\n",
        "\n",
        "print(accuracy_score(y_test2, y_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX3O5goduruX",
        "outputId": "e5835a28-29fa-4feb-9431-1c9cf6efa188"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy for class3 vs (class1 and class2)"
      ],
      "metadata": {
        "id": "n1iPNqKJ1CZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y3=[0 if y[i]==2 else 1 for i in range(len(y))]\n",
        "X_train3,X_test3,y_train3,y_test3 = train_test_split(X, y3, test_size=0.2)\n",
        "weights,bias = back_propagation(X_train3, y_train3, weights, bias, lr)\n",
        "y_pred3=[]\n",
        "for j in range(X_test3.shape[0]): \n",
        "    y_pred3.append(perceptron(X_test3[j],weights,bias))\n",
        "\n",
        "print(accuracy_score(y_test3, y_pred3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUiZZWE09bHg",
        "outputId": "18dfa80a-7a48-431d-f0f9-0939239dffe0"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2"
      ],
      "metadata": {
        "id": "YENI5ii_MZy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the IRIS dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "# print(type(y))\n",
        "# Encode the labels using one-hot encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "y = np.eye(3)[y]\n",
        "# def enc(col,name):\n",
        "#   x = LabelEncoder()\n",
        "#   lst  = x.fit_transform(y.iloc[:,col])\n",
        "#   y[name] = lst[:]\n",
        "# enc(0,'class')\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "# y_train=np.argmax(y_train, axis=1)\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self,input_layer,L1_size,L2_size,output_layer,n_iter,lr=0.01):\n",
        "        self.input_layer = input_layer\n",
        "        self.L1_size = L1_size\n",
        "        self.L2_size = L2_size\n",
        "        self.output_layer = output_layer\n",
        "        self.lr = lr\n",
        "        self.n_iter = n_iter\n",
        "        self.weights ={}\n",
        "        self.initialize_weights()\n",
        "    \n",
        "\n",
        "    #initializig weights\n",
        "    def initialize_weights(self):\n",
        "      self.weights[\"weights1\"] = np.random.randn(self.input_layer,self.L1_size)\n",
        "      self.weights[\"bias1\"] = np.random.randn(self.L1_size)\n",
        "      self.weights[\"weights2\"] = np.random.randn(self.L1_size,self.L2_size)\n",
        "      self.weights[\"bias2\"] = np.random.randn(self.L2_size)\n",
        "      self.weights[\"weights3\"] = np.random.randn(self.L2_size,self.output_layer)\n",
        "      self.weights[\"bias3\"] = np.random.randn(self.output_layer)\n",
        "    \n",
        "\n",
        "    def sigmoid(self,x):\n",
        "        return 1 / (1 +np.exp(-x))\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x *(1 - x)\n",
        "    def softmax(self,x):\n",
        "        return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
        "\n",
        "    # writing function for forward propagation\n",
        "    def forward_pass(self,X):\n",
        "\n",
        "        self.ll1= np.dot(X, self.weights[\"weights1\"]) + self.weights[\"bias1\"]\n",
        "        self.act1 = self.sigmoid(self.ll1)\n",
        "        self.ll2 = np.dot(self.act1, self.weights[\"weights2\"]) + self.weights[\"bias2\"]\n",
        "        self.act2= self.sigmoid(self.ll2)\n",
        "        #print('here')\n",
        "        self.ll3 = np.dot(self.act2, self.weights[\"weights3\"]) + self.weights[\"bias3\"]\n",
        "        self.act3 = self.softmax(self.ll3)\n",
        "        return self.act3\n",
        "    \n",
        "    #writing the funtion for backward propagation\n",
        "    def backward_pass(self, X, y):\n",
        "        layer3_error = self.act3 - y\n",
        "        layer2_error = np.dot(layer3_error, self.weights[\"weights3\"].T) * self.sigmoid_derivative(self.act2)\n",
        "        layer1_error = np.dot(layer2_error, self.weights[\"weights2\"].T) * self.sigmoid_derivative(self.act1)\n",
        "        \n",
        "        dweights3 = np.dot(self.act2.T, layer3_error)\n",
        "        dbias3 = np.sum(layer3_error, axis=0)\n",
        "        dweights2 = np.dot(self.act1.T, layer2_error)\n",
        "        dbias2 = np.sum(layer2_error,axis=0)\n",
        "        dweights1 = np.dot(X.T, layer1_error)\n",
        "        dbias1 = np.sum(layer1_error, axis=0)\n",
        "        self.weights[\"weights1\"] -= self.lr * dweights1\n",
        "        self.weights[\"bias1\"] -= self.lr * dbias1\n",
        "        self.weights[\"weights2\"] -= self.lr * dweights2\n",
        "        self.weights[\"bias2\"] -= self.lr * dbias2\n",
        "        self.weights[\"weights3\"] -= self.lr * dweights3\n",
        "        self.weights[\"bias3\"] -= self.lr * dbias3\n",
        "        # return 'completed'\n",
        "\n",
        "    # writing the function for fitting the model\n",
        "    def fit(self, X, y):\n",
        "        for i in range(self.n_iter):\n",
        "            #print('here')\n",
        "            self.forward_pass(X)\n",
        "            self.backward_pass(X, y)\n",
        "            print('iteration', i+1,'completed')\n",
        "        return self\n",
        "    \n",
        "    #predicting output\n",
        "    def predict(self, X):\n",
        "        return self.forward_pass(X)\n"
      ],
      "metadata": {
        "id": "ByUfuqGFGNlM"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "8FIE50sv4NZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(input_layer=4, L1_size=4, L2_size=5, output_layer=3, lr=0.001, n_iter=15)\n",
        "# print(y_train)\n",
        "y_train[1]\n",
        "# print(y_train)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "# print(y_pred)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nBfieU74LRm",
        "outputId": "4785e1f8-fd8e-42b4-e962-c3b30cb4ddb1"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1 completed\n",
            "iteration 2 completed\n",
            "iteration 3 completed\n",
            "iteration 4 completed\n",
            "iteration 5 completed\n",
            "iteration 6 completed\n",
            "iteration 7 completed\n",
            "iteration 8 completed\n",
            "iteration 9 completed\n",
            "iteration 10 completed\n",
            "iteration 11 completed\n",
            "iteration 12 completed\n",
            "iteration 13 completed\n",
            "iteration 14 completed\n",
            "iteration 15 completed\n",
            "Accuracy: 0.7333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fa2JZWDIMeMr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}